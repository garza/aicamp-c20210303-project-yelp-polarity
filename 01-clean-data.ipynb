{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01-clean-data\n",
    "\n",
    "## Main Objectives\n",
    "\n",
    "- Dataset inspection and sanity checking\n",
    "- Basic function based cleaning\n",
    "- SpaCy based cleaning and normalization\n",
    "- Saving cleaned dataset for subsequent notebooks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4N20UNLaQkTx",
    "outputId": "cd76b3fd-4a67-4df4-fbc4-404c1fda5676"
   },
   "outputs": [],
   "source": [
    "!ls\n",
    "##!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tu2RvhdMQwjj",
    "outputId": "23c51f61-da1b-43e0-d33a-edb6bad667e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score.png\t\t  yelp_reviews_stars.ipynb  yelp_train_df.csv\n",
      "yelp_review_polarity_csv  yelp_test_df.csv\n",
      "--2021-03-15 22:08:12--  https://s3.amazonaws.com/fast-ai-nlp/yelp_review_polarity_csv.tgz\n",
      "Resolving s3.amazonaws.com... 52.217.18.254\n",
      "Connecting to s3.amazonaws.com|52.217.18.254|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 166373201 (159M) [application/x-tar]\n",
      "Saving to: ‘yelp_review_polarity_csv.tgz’\n",
      "\n",
      "yelp_review_polarit 100%[===================>] 158.67M  20.5MB/s    in 8.3s    \n",
      "\n",
      "2021-03-15 22:08:26 (19.0 MB/s) - ‘yelp_review_polarity_csv.tgz’ saved [166373201/166373201]\n",
      "\n",
      "yelp_review_polarity_csv/\n",
      "yelp_review_polarity_csv/train.csv\n",
      "yelp_review_polarity_csv/readme.txt\n",
      "yelp_review_polarity_csv/test.csv\n"
     ]
    }
   ],
   "source": [
    "!ls\n",
    "!wget https://s3.amazonaws.com/fast-ai-nlp/yelp_review_polarity_csv.tgz -O yelp_review_polarity_csv.tgz\n",
    "!tar xzvf yelp_review_polarity_csv.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Vs3i2UcuQuxt"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import re\n",
    "import string\n",
    "from spacy.lang.en.examples import sentences \n",
    "from spacy import displacy\n",
    "from spacy.util import minibatch, compounding\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "import nltk\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load raw data, verify size of both sets (training and test)\n",
    "\n",
    "- We should have 560,000 rows for training and 38,000 rows for test/validation\n",
    "- Use head() to take a look at the current format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LC8v990a6lZS",
    "outputId": "f3d0757a-4a7a-4d62-c9c3-d81d3bafc5bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data set size:\n",
      "(560000, 2)\n",
      "test data set size:\n",
      "(38000, 2)\n"
     ]
    }
   ],
   "source": [
    "data_names=['Score', 'Raw']\n",
    "yelp_test_df=pd.read_csv('yelp_review_polarity_csv/test.csv', names=data_names)\n",
    "yelp_train_df=pd.read_csv('yelp_review_polarity_csv/train.csv', names=data_names)\n",
    "\n",
    "print('training data set size:')\n",
    "print(yelp_train_df.shape)\n",
    "print('test data set size:')\n",
    "print(yelp_test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "t25xX82xiyJq",
    "outputId": "9814de35-917b-4f2d-bba0-37292bc762e0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Unfortunately, the frustration of being Dr. Go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Been going to Dr. Goldberg for over 10 years. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>I don't know what Dr. Goldberg was like before...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>I'm writing this review to give you a heads up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>All the food is great here. But the best thing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Score                                                Raw\n",
       "0      1  Unfortunately, the frustration of being Dr. Go...\n",
       "1      2  Been going to Dr. Goldberg for over 10 years. ...\n",
       "2      1  I don't know what Dr. Goldberg was like before...\n",
       "3      1  I'm writing this review to give you a heads up...\n",
       "4      2  All the food is great here. But the best thing..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LkuAW5Arihwz"
   },
   "source": [
    "# Clean Up Pass #1\n",
    "\n",
    "Rudimentary function based text cleaning\n",
    "\n",
    "- remove extra new line characters\n",
    "- remove some special characters\n",
    "- for later datasets (commented out for now), remove punctuation and more special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "DdX_8YiveLjm"
   },
   "outputs": [],
   "source": [
    "def remove_special_characters(text, remove_digits=False):\n",
    "    pattern = r'[^a-zA-z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text\n",
    "\n",
    "def normalize_corpus(corpus):\n",
    "  normalized_corpus = []\n",
    "  for doc in corpus:\n",
    "    #doc = doc.lower()\n",
    "    doc = re.sub(r'[\\r|\\n|\\r\\n]+', ' ',doc)\n",
    "    doc = re.sub('\\\\\\\\n',' ',doc)\n",
    "    special_char_pattern = re.compile(r'([{.(-)!}])')\n",
    "    #doc = special_char_pattern.sub(\" \\\\1 \", doc)\n",
    "    #doc = remove_special_characters(doc, remove_digits=True)  \n",
    "    doc = re.sub(' +', ' ', doc)\n",
    "    normalized_corpus.append(doc)\n",
    "\n",
    "  return normalized_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on a sample review or two to verify cleaning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0VoV21qojE2j",
    "outputId": "4ff97506-1638-4c7c-ce5c-8dd434c37b55"
   },
   "outputs": [],
   "source": [
    "test = []\n",
    "print(yelp_train_df['Raw'][90])\n",
    "test.append(yelp_train_df['Raw'][90])\n",
    "print(yelp_train_df['Raw'][40])\n",
    "test.append(yelp_train_df['Raw'][40])\n",
    "test_clean = normalize_corpus(test)\n",
    "print(test_clean[0])\n",
    "print(test_clean[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save our first pass clean in our dataframe under 'Clean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "-sJjfGrZjKfq"
   },
   "outputs": [],
   "source": [
    "yelp_test_df['Clean'] = normalize_corpus(yelp_test_df['Raw'])\n",
    "yelp_train_df['Clean'] = normalize_corpus(yelp_train_df['Raw'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Up Pass #2\n",
    "Using SpaCy, remove stop works, lemmatize, lowercase, strip extra spaces and remove punctuation.  Only keep tokens identified as '-PRON-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8nYnL3k5fMlL",
    "outputId": "b6f0b7a9-f417-434e-b14e-c936965a9592"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stop words: 326\n",
      "First ten stop words: ['upon', 'do', 'her', 'also', 'seems', 'among', 'behind', 'he', 'take', 'whole']\n"
     ]
    }
   ],
   "source": [
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "print('Number of stop words: %d' % len(spacy_stopwords))\n",
    "print('First ten stop words: %s' % list(spacy_stopwords)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "xyBbkJjWZGY5"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.pipe_names\n",
    "punctuations = string.punctuation\n",
    "\n",
    "def cleanup_nlp_text(docs, logging=False):\n",
    "  texts = []\n",
    "  counter = 1\n",
    "  for doc in docs:\n",
    "    if counter % 10000 == 0 and logging:\n",
    "      print(\"%d out of %d\" % (counter, len(docs)))\n",
    "    counter += 1\n",
    "    doc = nlp(doc, disable=['parser', 'ner'])\n",
    "    tokens = [tok.lemma_.lower().strip() for tok in doc if tok.lemma_ != '-PRON-']\n",
    "    tokens = [tok for tok in tokens if tok not in spacy_stopwords and tok not in punctuations]\n",
    "    tokens = ' '.join(tokens)\n",
    "    texts.append(tokens)\n",
    "  return pd.Series(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply SpaCy cleanup_nlp_text to the 'Clean' dataset from Pass #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "akKamI5zlkM3",
    "outputId": "5bbef961-810e-4dcd-9df1-c80d061309d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 out of 38000\n",
      "2000 out of 38000\n",
      "3000 out of 38000\n",
      "4000 out of 38000\n",
      "5000 out of 38000\n",
      "6000 out of 38000\n",
      "7000 out of 38000\n",
      "8000 out of 38000\n",
      "9000 out of 38000\n",
      "10000 out of 38000\n",
      "11000 out of 38000\n",
      "12000 out of 38000\n",
      "13000 out of 38000\n",
      "14000 out of 38000\n",
      "15000 out of 38000\n",
      "16000 out of 38000\n",
      "17000 out of 38000\n",
      "18000 out of 38000\n",
      "19000 out of 38000\n",
      "20000 out of 38000\n",
      "21000 out of 38000\n",
      "22000 out of 38000\n",
      "23000 out of 38000\n",
      "24000 out of 38000\n",
      "25000 out of 38000\n",
      "26000 out of 38000\n",
      "27000 out of 38000\n",
      "28000 out of 38000\n",
      "29000 out of 38000\n",
      "30000 out of 38000\n",
      "31000 out of 38000\n",
      "32000 out of 38000\n",
      "33000 out of 38000\n",
      "34000 out of 38000\n",
      "35000 out of 38000\n",
      "36000 out of 38000\n",
      "37000 out of 38000\n",
      "38000 out of 38000\n"
     ]
    }
   ],
   "source": [
    "yelp_test_df['Text'] = cleanup_nlp_text(yelp_test_df['Clean'], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-UwCo0ZRkXQf",
    "outputId": "9787567e-15da-4152-907d-bbea2c51f55a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 out of 560000\n",
      "2000 out of 560000\n",
      "3000 out of 560000\n",
      "4000 out of 560000\n",
      "5000 out of 560000\n",
      "6000 out of 560000\n",
      "7000 out of 560000\n",
      "8000 out of 560000\n",
      "9000 out of 560000\n",
      "10000 out of 560000\n",
      "11000 out of 560000\n",
      "12000 out of 560000\n",
      "13000 out of 560000\n",
      "14000 out of 560000\n",
      "15000 out of 560000\n",
      "16000 out of 560000\n",
      "17000 out of 560000\n",
      "18000 out of 560000\n",
      "19000 out of 560000\n",
      "20000 out of 560000\n",
      "21000 out of 560000\n",
      "22000 out of 560000\n",
      "23000 out of 560000\n",
      "24000 out of 560000\n",
      "25000 out of 560000\n",
      "26000 out of 560000\n",
      "27000 out of 560000\n",
      "28000 out of 560000\n",
      "29000 out of 560000\n",
      "30000 out of 560000\n",
      "31000 out of 560000\n",
      "32000 out of 560000\n",
      "33000 out of 560000\n",
      "34000 out of 560000\n",
      "35000 out of 560000\n",
      "36000 out of 560000\n",
      "37000 out of 560000\n",
      "38000 out of 560000\n",
      "39000 out of 560000\n",
      "40000 out of 560000\n",
      "41000 out of 560000\n",
      "42000 out of 560000\n",
      "43000 out of 560000\n",
      "44000 out of 560000\n",
      "45000 out of 560000\n",
      "46000 out of 560000\n",
      "47000 out of 560000\n",
      "48000 out of 560000\n",
      "49000 out of 560000\n",
      "50000 out of 560000\n",
      "51000 out of 560000\n",
      "52000 out of 560000\n",
      "53000 out of 560000\n",
      "54000 out of 560000\n",
      "55000 out of 560000\n",
      "56000 out of 560000\n",
      "57000 out of 560000\n",
      "58000 out of 560000\n",
      "59000 out of 560000\n",
      "60000 out of 560000\n",
      "61000 out of 560000\n",
      "62000 out of 560000\n",
      "63000 out of 560000\n",
      "64000 out of 560000\n",
      "65000 out of 560000\n",
      "66000 out of 560000\n",
      "67000 out of 560000\n",
      "68000 out of 560000\n",
      "69000 out of 560000\n",
      "70000 out of 560000\n",
      "71000 out of 560000\n",
      "72000 out of 560000\n",
      "73000 out of 560000\n",
      "74000 out of 560000\n",
      "75000 out of 560000\n",
      "76000 out of 560000\n",
      "77000 out of 560000\n",
      "78000 out of 560000\n",
      "79000 out of 560000\n",
      "80000 out of 560000\n",
      "81000 out of 560000\n",
      "82000 out of 560000\n",
      "83000 out of 560000\n",
      "84000 out of 560000\n",
      "85000 out of 560000\n",
      "86000 out of 560000\n",
      "87000 out of 560000\n",
      "88000 out of 560000\n",
      "89000 out of 560000\n",
      "90000 out of 560000\n",
      "91000 out of 560000\n",
      "92000 out of 560000\n",
      "93000 out of 560000\n",
      "94000 out of 560000\n",
      "95000 out of 560000\n",
      "96000 out of 560000\n",
      "97000 out of 560000\n",
      "98000 out of 560000\n",
      "99000 out of 560000\n",
      "100000 out of 560000\n",
      "101000 out of 560000\n",
      "102000 out of 560000\n",
      "103000 out of 560000\n",
      "104000 out of 560000\n",
      "105000 out of 560000\n",
      "106000 out of 560000\n",
      "107000 out of 560000\n",
      "108000 out of 560000\n",
      "109000 out of 560000\n",
      "110000 out of 560000\n",
      "111000 out of 560000\n",
      "112000 out of 560000\n",
      "113000 out of 560000\n",
      "114000 out of 560000\n",
      "115000 out of 560000\n",
      "116000 out of 560000\n",
      "117000 out of 560000\n",
      "118000 out of 560000\n",
      "119000 out of 560000\n",
      "120000 out of 560000\n",
      "121000 out of 560000\n",
      "122000 out of 560000\n",
      "123000 out of 560000\n",
      "124000 out of 560000\n",
      "125000 out of 560000\n",
      "126000 out of 560000\n",
      "127000 out of 560000\n",
      "128000 out of 560000\n",
      "129000 out of 560000\n",
      "130000 out of 560000\n",
      "131000 out of 560000\n",
      "132000 out of 560000\n",
      "133000 out of 560000\n",
      "134000 out of 560000\n",
      "135000 out of 560000\n",
      "136000 out of 560000\n",
      "137000 out of 560000\n",
      "138000 out of 560000\n",
      "139000 out of 560000\n",
      "140000 out of 560000\n",
      "141000 out of 560000\n",
      "142000 out of 560000\n",
      "143000 out of 560000\n",
      "144000 out of 560000\n",
      "145000 out of 560000\n",
      "146000 out of 560000\n",
      "147000 out of 560000\n",
      "148000 out of 560000\n",
      "149000 out of 560000\n",
      "150000 out of 560000\n",
      "151000 out of 560000\n",
      "152000 out of 560000\n",
      "153000 out of 560000\n",
      "154000 out of 560000\n",
      "155000 out of 560000\n",
      "156000 out of 560000\n",
      "157000 out of 560000\n",
      "158000 out of 560000\n",
      "159000 out of 560000\n",
      "160000 out of 560000\n",
      "161000 out of 560000\n",
      "162000 out of 560000\n",
      "163000 out of 560000\n",
      "164000 out of 560000\n",
      "165000 out of 560000\n",
      "166000 out of 560000\n",
      "167000 out of 560000\n",
      "168000 out of 560000\n",
      "169000 out of 560000\n",
      "170000 out of 560000\n",
      "171000 out of 560000\n",
      "172000 out of 560000\n",
      "173000 out of 560000\n",
      "174000 out of 560000\n",
      "175000 out of 560000\n",
      "176000 out of 560000\n",
      "177000 out of 560000\n",
      "178000 out of 560000\n",
      "179000 out of 560000\n",
      "180000 out of 560000\n",
      "181000 out of 560000\n",
      "182000 out of 560000\n",
      "183000 out of 560000\n",
      "184000 out of 560000\n",
      "185000 out of 560000\n",
      "186000 out of 560000\n",
      "187000 out of 560000\n",
      "188000 out of 560000\n",
      "189000 out of 560000\n",
      "190000 out of 560000\n",
      "191000 out of 560000\n",
      "192000 out of 560000\n",
      "193000 out of 560000\n",
      "194000 out of 560000\n",
      "195000 out of 560000\n",
      "196000 out of 560000\n",
      "197000 out of 560000\n",
      "198000 out of 560000\n",
      "199000 out of 560000\n",
      "200000 out of 560000\n",
      "201000 out of 560000\n",
      "202000 out of 560000\n",
      "203000 out of 560000\n",
      "204000 out of 560000\n",
      "205000 out of 560000\n",
      "206000 out of 560000\n",
      "207000 out of 560000\n",
      "208000 out of 560000\n",
      "209000 out of 560000\n",
      "210000 out of 560000\n",
      "211000 out of 560000\n",
      "212000 out of 560000\n",
      "213000 out of 560000\n",
      "214000 out of 560000\n",
      "215000 out of 560000\n",
      "216000 out of 560000\n",
      "217000 out of 560000\n",
      "218000 out of 560000\n",
      "219000 out of 560000\n",
      "220000 out of 560000\n",
      "221000 out of 560000\n",
      "222000 out of 560000\n",
      "223000 out of 560000\n",
      "224000 out of 560000\n",
      "225000 out of 560000\n",
      "226000 out of 560000\n",
      "227000 out of 560000\n",
      "228000 out of 560000\n",
      "229000 out of 560000\n",
      "230000 out of 560000\n",
      "231000 out of 560000\n",
      "232000 out of 560000\n",
      "233000 out of 560000\n",
      "234000 out of 560000\n",
      "235000 out of 560000\n",
      "236000 out of 560000\n",
      "237000 out of 560000\n",
      "238000 out of 560000\n",
      "239000 out of 560000\n",
      "240000 out of 560000\n",
      "241000 out of 560000\n",
      "242000 out of 560000\n",
      "243000 out of 560000\n",
      "244000 out of 560000\n",
      "245000 out of 560000\n",
      "246000 out of 560000\n",
      "247000 out of 560000\n",
      "248000 out of 560000\n",
      "249000 out of 560000\n",
      "250000 out of 560000\n",
      "251000 out of 560000\n",
      "252000 out of 560000\n",
      "253000 out of 560000\n",
      "254000 out of 560000\n",
      "255000 out of 560000\n",
      "256000 out of 560000\n",
      "257000 out of 560000\n",
      "258000 out of 560000\n",
      "259000 out of 560000\n",
      "260000 out of 560000\n",
      "261000 out of 560000\n",
      "262000 out of 560000\n",
      "263000 out of 560000\n",
      "264000 out of 560000\n",
      "265000 out of 560000\n",
      "266000 out of 560000\n",
      "267000 out of 560000\n",
      "268000 out of 560000\n",
      "269000 out of 560000\n",
      "270000 out of 560000\n",
      "271000 out of 560000\n",
      "272000 out of 560000\n",
      "273000 out of 560000\n",
      "274000 out of 560000\n",
      "275000 out of 560000\n",
      "276000 out of 560000\n",
      "277000 out of 560000\n",
      "278000 out of 560000\n",
      "279000 out of 560000\n",
      "280000 out of 560000\n",
      "281000 out of 560000\n",
      "282000 out of 560000\n",
      "283000 out of 560000\n",
      "284000 out of 560000\n",
      "285000 out of 560000\n",
      "286000 out of 560000\n",
      "287000 out of 560000\n",
      "288000 out of 560000\n",
      "289000 out of 560000\n",
      "290000 out of 560000\n",
      "291000 out of 560000\n",
      "292000 out of 560000\n",
      "293000 out of 560000\n",
      "294000 out of 560000\n",
      "295000 out of 560000\n",
      "296000 out of 560000\n",
      "297000 out of 560000\n",
      "298000 out of 560000\n",
      "299000 out of 560000\n",
      "300000 out of 560000\n",
      "301000 out of 560000\n",
      "302000 out of 560000\n",
      "303000 out of 560000\n",
      "304000 out of 560000\n",
      "305000 out of 560000\n",
      "306000 out of 560000\n",
      "307000 out of 560000\n",
      "308000 out of 560000\n",
      "309000 out of 560000\n",
      "310000 out of 560000\n",
      "311000 out of 560000\n",
      "312000 out of 560000\n",
      "313000 out of 560000\n",
      "314000 out of 560000\n",
      "315000 out of 560000\n",
      "316000 out of 560000\n",
      "317000 out of 560000\n",
      "318000 out of 560000\n",
      "319000 out of 560000\n",
      "320000 out of 560000\n",
      "321000 out of 560000\n",
      "322000 out of 560000\n",
      "323000 out of 560000\n",
      "324000 out of 560000\n",
      "325000 out of 560000\n",
      "326000 out of 560000\n",
      "327000 out of 560000\n",
      "328000 out of 560000\n",
      "329000 out of 560000\n",
      "330000 out of 560000\n",
      "331000 out of 560000\n",
      "332000 out of 560000\n",
      "333000 out of 560000\n",
      "334000 out of 560000\n",
      "335000 out of 560000\n",
      "336000 out of 560000\n",
      "337000 out of 560000\n",
      "338000 out of 560000\n",
      "339000 out of 560000\n",
      "340000 out of 560000\n",
      "341000 out of 560000\n",
      "342000 out of 560000\n",
      "343000 out of 560000\n",
      "344000 out of 560000\n",
      "345000 out of 560000\n",
      "346000 out of 560000\n",
      "347000 out of 560000\n",
      "348000 out of 560000\n",
      "349000 out of 560000\n",
      "350000 out of 560000\n",
      "351000 out of 560000\n",
      "352000 out of 560000\n",
      "353000 out of 560000\n",
      "354000 out of 560000\n",
      "355000 out of 560000\n",
      "356000 out of 560000\n",
      "357000 out of 560000\n",
      "358000 out of 560000\n",
      "359000 out of 560000\n",
      "360000 out of 560000\n",
      "361000 out of 560000\n",
      "362000 out of 560000\n",
      "363000 out of 560000\n",
      "364000 out of 560000\n",
      "365000 out of 560000\n",
      "366000 out of 560000\n",
      "367000 out of 560000\n",
      "368000 out of 560000\n",
      "369000 out of 560000\n",
      "370000 out of 560000\n",
      "371000 out of 560000\n",
      "372000 out of 560000\n",
      "373000 out of 560000\n",
      "374000 out of 560000\n",
      "375000 out of 560000\n",
      "376000 out of 560000\n",
      "377000 out of 560000\n",
      "378000 out of 560000\n",
      "379000 out of 560000\n",
      "380000 out of 560000\n",
      "381000 out of 560000\n",
      "382000 out of 560000\n",
      "383000 out of 560000\n",
      "384000 out of 560000\n",
      "385000 out of 560000\n",
      "386000 out of 560000\n",
      "387000 out of 560000\n",
      "388000 out of 560000\n",
      "389000 out of 560000\n",
      "390000 out of 560000\n",
      "391000 out of 560000\n",
      "392000 out of 560000\n",
      "393000 out of 560000\n",
      "394000 out of 560000\n",
      "395000 out of 560000\n",
      "396000 out of 560000\n",
      "397000 out of 560000\n",
      "398000 out of 560000\n",
      "399000 out of 560000\n",
      "400000 out of 560000\n",
      "401000 out of 560000\n",
      "402000 out of 560000\n",
      "403000 out of 560000\n",
      "404000 out of 560000\n",
      "405000 out of 560000\n",
      "406000 out of 560000\n",
      "407000 out of 560000\n",
      "408000 out of 560000\n",
      "409000 out of 560000\n",
      "410000 out of 560000\n",
      "411000 out of 560000\n",
      "412000 out of 560000\n",
      "413000 out of 560000\n",
      "414000 out of 560000\n",
      "415000 out of 560000\n",
      "416000 out of 560000\n",
      "417000 out of 560000\n",
      "418000 out of 560000\n",
      "419000 out of 560000\n",
      "420000 out of 560000\n",
      "421000 out of 560000\n",
      "422000 out of 560000\n",
      "423000 out of 560000\n",
      "424000 out of 560000\n",
      "425000 out of 560000\n",
      "426000 out of 560000\n",
      "427000 out of 560000\n",
      "428000 out of 560000\n",
      "429000 out of 560000\n",
      "430000 out of 560000\n",
      "431000 out of 560000\n",
      "432000 out of 560000\n",
      "433000 out of 560000\n",
      "434000 out of 560000\n",
      "435000 out of 560000\n",
      "436000 out of 560000\n",
      "437000 out of 560000\n",
      "438000 out of 560000\n",
      "439000 out of 560000\n",
      "440000 out of 560000\n",
      "441000 out of 560000\n",
      "442000 out of 560000\n",
      "443000 out of 560000\n",
      "444000 out of 560000\n",
      "445000 out of 560000\n",
      "446000 out of 560000\n",
      "447000 out of 560000\n",
      "448000 out of 560000\n",
      "449000 out of 560000\n",
      "450000 out of 560000\n",
      "451000 out of 560000\n",
      "452000 out of 560000\n",
      "453000 out of 560000\n",
      "454000 out of 560000\n",
      "455000 out of 560000\n",
      "456000 out of 560000\n",
      "457000 out of 560000\n",
      "458000 out of 560000\n",
      "459000 out of 560000\n",
      "460000 out of 560000\n",
      "461000 out of 560000\n",
      "462000 out of 560000\n",
      "463000 out of 560000\n",
      "464000 out of 560000\n",
      "465000 out of 560000\n",
      "466000 out of 560000\n",
      "467000 out of 560000\n",
      "468000 out of 560000\n",
      "469000 out of 560000\n",
      "470000 out of 560000\n",
      "471000 out of 560000\n",
      "472000 out of 560000\n",
      "473000 out of 560000\n",
      "474000 out of 560000\n",
      "475000 out of 560000\n",
      "476000 out of 560000\n",
      "477000 out of 560000\n",
      "478000 out of 560000\n",
      "479000 out of 560000\n",
      "480000 out of 560000\n",
      "481000 out of 560000\n",
      "482000 out of 560000\n",
      "483000 out of 560000\n",
      "484000 out of 560000\n",
      "485000 out of 560000\n",
      "486000 out of 560000\n",
      "487000 out of 560000\n",
      "488000 out of 560000\n",
      "489000 out of 560000\n",
      "490000 out of 560000\n",
      "491000 out of 560000\n",
      "492000 out of 560000\n",
      "493000 out of 560000\n",
      "494000 out of 560000\n",
      "495000 out of 560000\n",
      "496000 out of 560000\n",
      "497000 out of 560000\n",
      "498000 out of 560000\n",
      "499000 out of 560000\n",
      "500000 out of 560000\n",
      "501000 out of 560000\n",
      "502000 out of 560000\n",
      "503000 out of 560000\n",
      "504000 out of 560000\n",
      "505000 out of 560000\n",
      "506000 out of 560000\n",
      "507000 out of 560000\n",
      "508000 out of 560000\n",
      "509000 out of 560000\n",
      "510000 out of 560000\n",
      "511000 out of 560000\n",
      "512000 out of 560000\n",
      "513000 out of 560000\n",
      "514000 out of 560000\n",
      "515000 out of 560000\n",
      "516000 out of 560000\n",
      "517000 out of 560000\n",
      "518000 out of 560000\n",
      "519000 out of 560000\n",
      "520000 out of 560000\n",
      "521000 out of 560000\n",
      "522000 out of 560000\n",
      "523000 out of 560000\n",
      "524000 out of 560000\n",
      "525000 out of 560000\n",
      "526000 out of 560000\n",
      "527000 out of 560000\n",
      "528000 out of 560000\n",
      "529000 out of 560000\n",
      "530000 out of 560000\n",
      "531000 out of 560000\n",
      "532000 out of 560000\n",
      "533000 out of 560000\n",
      "534000 out of 560000\n",
      "535000 out of 560000\n",
      "536000 out of 560000\n",
      "537000 out of 560000\n",
      "538000 out of 560000\n",
      "539000 out of 560000\n",
      "540000 out of 560000\n",
      "541000 out of 560000\n",
      "542000 out of 560000\n",
      "543000 out of 560000\n",
      "544000 out of 560000\n",
      "545000 out of 560000\n",
      "546000 out of 560000\n",
      "547000 out of 560000\n",
      "548000 out of 560000\n",
      "549000 out of 560000\n",
      "550000 out of 560000\n",
      "551000 out of 560000\n",
      "552000 out of 560000\n",
      "553000 out of 560000\n",
      "554000 out of 560000\n",
      "555000 out of 560000\n",
      "556000 out of 560000\n",
      "557000 out of 560000\n",
      "558000 out of 560000\n",
      "559000 out of 560000\n",
      "560000 out of 560000\n"
     ]
    }
   ],
   "source": [
    "yelp_train_df['Text'] = cleanup_nlp_text(yelp_train_df['Clean'], True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop any rows with missing values, readjust polarity scores to either 0 (negative) or 1 (positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "quVzyiXylI59"
   },
   "outputs": [],
   "source": [
    "yelp_test_df = yelp_test_df[['Text', 'Score']].dropna()\n",
    "yelp_train_df = yelp_train_df[['Text', 'Score']].dropna()\n",
    "\n",
    "yelp_train_df.loc[yelp_train_df.Score <= 1, \"Score\"] = 0\n",
    "yelp_train_df.loc[yelp_train_df.Score >= 2, \"Score\"] = 1\n",
    "yelp_test_df.loc[yelp_test_df.Score <= 1, \"Score\"] = 0\n",
    "yelp_test_df.loc[yelp_test_df.Score >= 2, \"Score\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save our dataframes back to csv for later notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "k7uT4TuBX4tb"
   },
   "outputs": [],
   "source": [
    "yelp_test_df.to_csv('yelp_test_df.csv', encoding='utf-8')\n",
    "yelp_train_df.to_csv('yelp_train_df.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also take a look and verify we have indeed saved cleaned up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "-ZOGJie-nkNz"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unfortunately frustration dr. goldberg patient...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dr. goldberg 10 year think 1st patient start m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>know dr. goldberg like arizona let tell stay a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>write review head doctor office staff administ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>food great good thing wing wing simply fantast...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Score\n",
       "0  unfortunately frustration dr. goldberg patient...      0\n",
       "1  dr. goldberg 10 year think 1st patient start m...      1\n",
       "2  know dr. goldberg like arizona let tell stay a...      0\n",
       "3  write review head doctor office staff administ...      0\n",
       "4  food great good thing wing wing simply fantast...      1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_reviews_df = yelp_train_df\n",
    "yelp_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UC65oWLY-URE",
    "outputId": "12315d34-a26f-41db-c4b3-903cc0c49602"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-clean-data.ipynb\t\t      evaluate\n",
      "02-prepare-spacy-docs.ipynb\t      models\n",
      "03-build-model-basic.ipynb\t      scratch-testing.ipynb\n",
      "04-build-model-TextCatBOW.ipynb       test-scores.png\n",
      "05-build-model-TextCatCNN.ipynb       train-scores.png\n",
      "06-build-model-TextCatEnsemble.ipynb  yelp_review_polarity_csv\n",
      "07-evaluate-review.ipynb\t      yelp_review_polarity_csv.tgz\n",
      "config\t\t\t\t      yelp_test_df.csv\n",
      "data\t\t\t\t      yelp_train_df.csv\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "id": "6lVafuS9UY9D",
    "outputId": "6af33b3b-6931-4a82-b309-0839b8973aee"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax=yelp_reviews_df.Score.value_counts().plot(kind='bar')\n",
    "fig = ax.get_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "8LCgHZhPWCj6",
    "outputId": "4d190c0c-a281-4dc6-801b-fb0041b128c4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unfortunately frustration dr. goldberg patient...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dr. goldberg 10 year think 1st patient start m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>know dr. goldberg like arizona let tell stay a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>write review head doctor office staff administ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>food great good thing wing wing simply fantast...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Score\n",
       "0  unfortunately frustration dr. goldberg patient...      0\n",
       "1  dr. goldberg 10 year think 1st patient start m...      1\n",
       "2  know dr. goldberg like arizona let tell stay a...      0\n",
       "3  write review head doctor office staff administ...      0\n",
       "4  food great good thing wing wing simply fantast...      1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_reviews_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More verification and preprocessing\n",
    "\n",
    "- Taken from Sessions 1-3 from [yasheshshroff-labs-notebooks](https://github.com/yasheshshroff/NLPworkshop/tree/main/labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kaotIGsAYwjU",
    "outputId": "36a24535-6f83-4719-d795-828e5196e0e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pos_df=yelp_reviews_df[yelp_reviews_df.Score==1][:125000]\n",
    "train_neg_df=yelp_reviews_df[yelp_reviews_df.Score==0][:125000]\n",
    "\n",
    "train_df=train_pos_df.append(train_neg_df)\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pHKdHKVKZDBk"
   },
   "source": [
    "Let's parse a review and go thru the SpaCy exercises to verify any future processing will be ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "Tn7vf06dZk2q",
    "outputId": "f37fd332-19ed-4b55-d833-d213b114d4e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"okay hopefully enjoy happy hour riley pour house read able follow lilting irish owner recap murphy pour house 1979 1985 sullivan pour house 1995 2002 paddy pour house 2002 2012 bagpipe riley pour house open march 1 2012 tiny long bar like old irish pub smoking allow hurrah lousy service guess entire place need strike .... demand automate food beverage ticketing system cook bartender waitress know order ticket belong table actually pretty funny hungry b thirsty want place need irish pub local old time water hole murphy ... er mean sullivan's .... er mean paddy riley case cold guinness irish music fun patron\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_review = yelp_reviews_df.Text[40]\n",
    "sample_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "HVx8DpzZ72DG",
    "outputId": "07d3ebcf-7a25-4361-92b6-b203850b4911"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'starbucks teeny tiny seating inside limited starbucks grab continue shopping waterfront baristas friendly fast'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_review = yelp_reviews_df.Text[90]\n",
    "sample_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "5MuEPIlKZqaB",
    "outputId": "ca5cfb64-1b08-4fc7-8bab-dc8ae18b1d2e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Companies, agencies, institutions, etc.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_review = nlp(sample_review)\n",
    "parsed_review\n",
    "\n",
    "for ent in parsed_review.ents:\n",
    "  print(ent.text, ent.label_, ent.doc)\n",
    "\n",
    "spacy.explain('ORG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "id": "1iF64g2-Z3u2",
    "outputId": "2df07e88-4b1c-4013-966e-c44976ca4f43"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>dep</th>\n",
       "      <th>shape</th>\n",
       "      <th>is_alpha</th>\n",
       "      <th>is_stop</th>\n",
       "      <th>is_punctuation</th>\n",
       "      <th>ent_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>starbucks</td>\n",
       "      <td>starbuck</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>teeny</td>\n",
       "      <td>teeny</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBP</td>\n",
       "      <td>xcomp</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tiny</td>\n",
       "      <td>tiny</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>amod</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>seating</td>\n",
       "      <td>seating</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>dobj</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>inside</td>\n",
       "      <td>inside</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>prep</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>limited</td>\n",
       "      <td>limited</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>amod</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>starbucks</td>\n",
       "      <td>starbuck</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>compound</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>grab</td>\n",
       "      <td>grab</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>pobj</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>continue</td>\n",
       "      <td>continue</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBP</td>\n",
       "      <td>conj</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>shopping</td>\n",
       "      <td>shopping</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>compound</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>waterfront</td>\n",
       "      <td>waterfront</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>baristas</td>\n",
       "      <td>barista</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>xcomp</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>friendly</td>\n",
       "      <td>friendly</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>amod</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>fast</td>\n",
       "      <td>fast</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          text       lemma   pos  tag       dep shape is_alpha is_stop  \\\n",
       "0    starbucks    starbuck  VERB  VBZ      ROOT  xxxx     True   False   \n",
       "1        teeny       teeny  VERB  VBP     xcomp  xxxx     True   False   \n",
       "2         tiny        tiny   ADJ   JJ      amod  xxxx     True   False   \n",
       "3      seating     seating  NOUN   NN      dobj  xxxx     True   False   \n",
       "4       inside      inside   ADP   IN      prep  xxxx     True   False   \n",
       "5      limited     limited   ADJ   JJ      amod  xxxx     True   False   \n",
       "6    starbucks    starbuck  NOUN  NNS  compound  xxxx     True   False   \n",
       "7         grab        grab  NOUN   NN      pobj  xxxx     True   False   \n",
       "8     continue    continue  VERB  VBP      conj  xxxx     True   False   \n",
       "9     shopping    shopping  NOUN   NN  compound  xxxx     True   False   \n",
       "10  waterfront  waterfront  NOUN   NN     nsubj  xxxx     True   False   \n",
       "11    baristas     barista  VERB  VBZ     xcomp  xxxx     True   False   \n",
       "12    friendly    friendly   ADJ   JJ      amod  xxxx     True   False   \n",
       "13        fast        fast   ADJ   JJ      ROOT  xxxx     True   False   \n",
       "\n",
       "   is_punctuation  ent_id  \n",
       "0           False     0.0  \n",
       "1           False     0.0  \n",
       "2           False     0.0  \n",
       "3           False     0.0  \n",
       "4           False     0.0  \n",
       "5           False     0.0  \n",
       "6           False     0.0  \n",
       "7           False     0.0  \n",
       "8           False     0.0  \n",
       "9           False     0.0  \n",
       "10          False     0.0  \n",
       "11          False     0.0  \n",
       "12          False     0.0  \n",
       "13          False     0.0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text = pd.DataFrame()\n",
    "\n",
    "for i, token in enumerate(parsed_review):\n",
    "    tokenized_text.loc[i, 'text'] = token.text\n",
    "    tokenized_text.loc[i, 'lemma'] = token.lemma_,\n",
    "    tokenized_text.loc[i, 'pos'] = token.pos_\n",
    "    tokenized_text.loc[i, 'tag'] = token.tag_\n",
    "    tokenized_text.loc[i, 'dep'] = token.dep_\n",
    "    tokenized_text.loc[i, 'shape'] = token.shape_\n",
    "    tokenized_text.loc[i, 'is_alpha'] = token.is_alpha\n",
    "    tokenized_text.loc[i, 'is_stop'] = token.is_stop\n",
    "    tokenized_text.loc[i, 'is_punctuation'] = token.is_punct\n",
    "    tokenized_text.loc[i, 'ent_id'] = token.ent_id\n",
    "\n",
    "tokenized_text[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "chQEJqPzaFoU",
    "outputId": "c3471f02-91b6-4bf1-f66b-7ccdc7287ab7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/garza/.local/lib/python3.7/site-packages/spacy/displacy/__init__.py:189: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
      "  warnings.warn(Warnings.W006)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">starbucks teeny tiny seating inside limited starbucks grab continue shopping waterfront baristas friendly fast</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "displacy.render(parsed_review, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q4qCajXYAd_J"
   },
   "source": [
    "Dependency parsing\n",
    "Identifies sentences, assigning a syntactic structure to it (subject-object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PcImTXWeAJYM",
    "outputId": "1e593fb0-cc94-4fe5-95f6-417be2064789"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[starbucks teeny tiny seating inside limited starbucks grab continue shopping waterfront baristas,\n",
       " friendly fast]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_spans = list(parsed_review.sents)\n",
    "sentence_spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "id": "ON8JlEndAk0e",
    "outputId": "8434bd37-fa3d-43ae-98d0-98f29034a721"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"77c257f4d99d4d24a687a941a8a76945-0\" class=\"displacy\" width=\"1170\" height=\"297.0\" direction=\"ltr\" style=\"max-width: none; height: 297.0px; color: green; background: white; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"207.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">starbucks</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"207.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"130\">teeny</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"130\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"207.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"210\">tiny</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"210\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"207.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"290\">seating</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"290\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"207.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"370\">inside</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"370\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"207.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"450\">limited</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"450\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"207.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"530\">starbucks</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"530\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"207.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"610\">grab</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"610\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"207.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"690\">continue</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"690\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"207.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">shopping</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"207.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"850\">waterfront</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"850\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"207.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"930\">baristas</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"930\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"207.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1010\">friendly</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1010\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"207.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1090\">fast</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1090\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-77c257f4d99d4d24a687a941a8a76945-0-0\" stroke-width=\"2px\" d=\"M62,162.0 62,148.66666666666666 121.0,148.66666666666666 121.0,162.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-77c257f4d99d4d24a687a941a8a76945-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M121.0,164.0 L125.0,156.0 117.0,156.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-77c257f4d99d4d24a687a941a8a76945-0-1\" stroke-width=\"2px\" d=\"M222,162.0 222,148.66666666666666 281.0,148.66666666666666 281.0,162.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-77c257f4d99d4d24a687a941a8a76945-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M222,164.0 L218,156.0 226,156.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-77c257f4d99d4d24a687a941a8a76945-0-2\" stroke-width=\"2px\" d=\"M142,162.0 142,135.33333333333334 284.0,135.33333333333334 284.0,162.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-77c257f4d99d4d24a687a941a8a76945-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M284.0,164.0 L288.0,156.0 280.0,156.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-77c257f4d99d4d24a687a941a8a76945-0-3\" stroke-width=\"2px\" d=\"M142,162.0 142,122.0 367.0,122.0 367.0,162.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-77c257f4d99d4d24a687a941a8a76945-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M367.0,164.0 L371.0,156.0 363.0,156.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-77c257f4d99d4d24a687a941a8a76945-0-4\" stroke-width=\"2px\" d=\"M462,162.0 462,148.66666666666666 521.0,148.66666666666666 521.0,162.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-77c257f4d99d4d24a687a941a8a76945-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M462,164.0 L458,156.0 466,156.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-77c257f4d99d4d24a687a941a8a76945-0-5\" stroke-width=\"2px\" d=\"M542,162.0 542,148.66666666666666 601.0,148.66666666666666 601.0,162.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-77c257f4d99d4d24a687a941a8a76945-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M542,164.0 L538,156.0 546,156.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-77c257f4d99d4d24a687a941a8a76945-0-6\" stroke-width=\"2px\" d=\"M382,162.0 382,122.0 607.0,122.0 607.0,162.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-77c257f4d99d4d24a687a941a8a76945-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M607.0,164.0 L611.0,156.0 603.0,156.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-77c257f4d99d4d24a687a941a8a76945-0-7\" stroke-width=\"2px\" d=\"M62,162.0 62,108.66666666666666 690.0,108.66666666666666 690.0,162.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-77c257f4d99d4d24a687a941a8a76945-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M690.0,164.0 L694.0,156.0 686.0,156.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-77c257f4d99d4d24a687a941a8a76945-0-8\" stroke-width=\"2px\" d=\"M782,162.0 782,148.66666666666666 841.0,148.66666666666666 841.0,162.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-77c257f4d99d4d24a687a941a8a76945-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M782,164.0 L778,156.0 786,156.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-77c257f4d99d4d24a687a941a8a76945-0-9\" stroke-width=\"2px\" d=\"M862,162.0 862,148.66666666666666 921.0,148.66666666666666 921.0,162.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-77c257f4d99d4d24a687a941a8a76945-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M862,164.0 L858,156.0 866,156.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-77c257f4d99d4d24a687a941a8a76945-0-10\" stroke-width=\"2px\" d=\"M702,162.0 702,122.0 927.0,122.0 927.0,162.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-77c257f4d99d4d24a687a941a8a76945-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M927.0,164.0 L931.0,156.0 923.0,156.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-77c257f4d99d4d24a687a941a8a76945-0-11\" stroke-width=\"2px\" d=\"M1022,162.0 1022,148.66666666666666 1081.0,148.66666666666666 1081.0,162.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-77c257f4d99d4d24a687a941a8a76945-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1022,164.0 L1018,156.0 1026,156.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "options = {'compact': True, 'bg': 'white','distance': 80,\n",
    "           'color': 'green', 'font': 'Arial'}\n",
    "displacy.render(parsed_review, jupyter=True, style='dep', options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6lKDAuGB5P-"
   },
   "source": [
    "## Processing noun chunks \n",
    "\n",
    "The dependency parser adds the `token.dep` and `token.head` attributes\n",
    "Further, it is also responsible for **noun chunks**: detecting sentences and base noun phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "TaxCtqiBB8uC",
    "outputId": "fe1b5ca2-4335-4b53-e342-01c26c06261d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>root</th>\n",
       "      <th>root.text</th>\n",
       "      <th>root.dep_</th>\n",
       "      <th>root.head.text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tiny seating</td>\n",
       "      <td>seating</td>\n",
       "      <td>seating</td>\n",
       "      <td>dobj</td>\n",
       "      <td>teeny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>limited starbucks grab</td>\n",
       "      <td>(grab,)</td>\n",
       "      <td>(grab,)</td>\n",
       "      <td>pobj</td>\n",
       "      <td>inside</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shopping waterfront</td>\n",
       "      <td>(waterfront,)</td>\n",
       "      <td>(waterfront,)</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>baristas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     text           root      root.text root.dep_  \\\n",
       "0            tiny seating        seating        seating      dobj   \n",
       "1  limited starbucks grab        (grab,)        (grab,)      pobj   \n",
       "2     shopping waterfront  (waterfront,)  (waterfront,)     nsubj   \n",
       "\n",
       "  root.head.text  \n",
       "0          teeny  \n",
       "1         inside  \n",
       "2       baristas  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_chunks_df = pd.DataFrame()\n",
    "\n",
    "for i, chunk in enumerate(parsed_review.noun_chunks):\n",
    "    noun_chunks_df.loc[i, 'text'] = chunk.text\n",
    "    noun_chunks_df.loc[i, 'root'] = chunk.root,\n",
    "    noun_chunks_df.loc[i, 'root.text'] = chunk.root.text,\n",
    "    noun_chunks_df.loc[i, 'root.dep_'] = chunk.root.dep_\n",
    "    noun_chunks_df.loc[i, 'root.head.text'] = chunk.root.head.text\n",
    "\n",
    "noun_chunks_df[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "6SWu3vXhFDZT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-clean-data.ipynb\t\t      evaluate\n",
      "02-prepare-spacy-docs.ipynb\t      models\n",
      "03-build-model-basic.ipynb\t      scratch-testing.ipynb\n",
      "04-build-model-TextCatBOW.ipynb       test-scores.png\n",
      "05-build-model-TextCatCNN.ipynb       train-scores.png\n",
      "06-build-model-TextCatEnsemble.ipynb  yelp_review_polarity_csv\n",
      "07-evaluate-review.ipynb\t      yelp_review_polarity_csv.tgz\n",
      "config\t\t\t\t      yelp_test_df.csv\n",
      "data\t\t\t\t      yelp_train_df.csv\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "yelp-reviews-stars.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
