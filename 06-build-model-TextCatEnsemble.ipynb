{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "seeing-maine",
   "metadata": {},
   "source": [
    "# 06-build-model-TextCatEnsemble\n",
    "\n",
    "## Main objectives:\n",
    "\n",
    "- Use spaCy's TextCatEnsemble to train a stacked ensemble of a linear bag-of-words model and a neural network model.\n",
    "    - [https://spacy.io/api/architectures#TextCatEnsemble](https://spacy.io/api/architectures#TextCatEnsemble)\n",
    "- Use spaCy generated docs to train this model\n",
    "- Run basic validation and evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "compact-milwaukee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "# load an english language model in spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "located-ordinance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev.spacy  train.spacy\n"
     ]
    }
   ],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "leading-martial",
   "metadata": {},
   "source": [
    "# Validate configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "german-official",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "============================= Config validation =============================\u001b[0m\n",
      "\u001b[1m\n",
      "===================== Config validation for [initialize] =====================\u001b[0m\n",
      "\u001b[1m\n",
      "====================== Config validation for [training] ======================\u001b[0m\n",
      "\u001b[38;5;2m‚úî Config is valid\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# validate configuration\n",
    "!python -m spacy debug config ./config/config-TextCatEnsemble.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "blocked-vampire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "============================ Data file validation ============================\u001b[0m\n",
      "\u001b[38;5;2m‚úî Corpus is loadable\u001b[0m\n",
      "\u001b[38;5;2m‚úî Pipeline can be initialized with data\u001b[0m\n",
      "\u001b[1m\n",
      "=============================== Training stats ===============================\u001b[0m\n",
      "Language: en\n",
      "Training pipeline: tok2vec, textcat\n",
      "5000 training docs\n",
      "5000 evaluation docs\n",
      "\u001b[38;5;2m‚úî No overlap between training and evaluation data\u001b[0m\n",
      "\u001b[1m\n",
      "============================== Vocab & Vectors ==============================\u001b[0m\n",
      "\u001b[38;5;4m‚Ñπ 282161 total word(s) in the data (18163 unique)\u001b[0m\n",
      "\u001b[38;5;4m‚Ñπ No word vectors present in the package\u001b[0m\n",
      "\u001b[1m\n",
      "================================== Summary ==================================\u001b[0m\n",
      "\u001b[38;5;2m‚úî 3 checks passed\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy debug data ./config/config-TextCatEnsemble.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggregate-jacob",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-bibliography",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4m‚Ñπ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2021-03-22 22:42:33,917] [INFO] Set up nlp object from config\n",
      "[2021-03-22 22:42:34,439] [INFO] Pipeline: ['tok2vec', 'textcat']\n",
      "[2021-03-22 22:42:34,459] [INFO] Created vocabulary\n",
      "[2021-03-22 22:42:34,459] [INFO] Finished initializing nlp object\n",
      "[2021-03-22 22:42:49,172] [INFO] Initialized pipeline components: ['tok2vec', 'textcat']\n",
      "\u001b[38;5;2m‚úî Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4m‚Ñπ Pipeline: ['tok2vec', 'textcat']\u001b[0m\n",
      "\u001b[38;5;4m‚Ñπ Initial learn rate: 0.001\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.23\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mtrue-bird-19\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/garza/yelp-polarity\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/garza/yelp-polarity/runs/31v8ob3l\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /home/garza/notebooks/aicamp/yelp-project/wandb/run-20210322_224254-31v8ob3l\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
      "\n",
      "E    #       LOSS TOK2VEC  LOSS TEXTCAT  CATS_SCORE  SCORE \n",
      "---  ------  ------------  ------------  ----------  ------\n",
      "  0       0          0.00          0.50       50.62    0.51\n",
      "  0      10          0.00          3.71       51.88    0.52\n",
      "  0      20          0.00          2.59       57.91    0.58\n",
      "  0      30          0.00          3.96       60.87    0.61\n",
      "  0      40          0.00          2.98       64.33    0.64\n",
      "  0      50          0.00          3.06       60.77    0.61\n",
      "  0      60          0.00          4.20       60.70    0.61\n",
      "  0      70          0.00          3.32       65.62    0.66\n",
      "  0      80          0.00          3.32       67.08    0.67\n",
      "  0      90          0.00          3.78       72.20    0.72\n",
      "  0     100          0.00          2.47       72.61    0.73\n",
      "  0     110          0.00          4.67       72.05    0.72\n",
      "  0     120          0.00          3.71       74.16    0.74\n",
      "  0     130          0.00          4.55       73.78    0.74\n",
      "  0     140          0.00          2.06       71.06    0.71\n",
      "  0     150          0.00          4.52       72.09    0.72\n",
      "  0     160          0.00          0.81       73.94    0.74\n",
      "  0     170          0.00          1.93       76.05    0.76\n",
      "  0     180          0.00          2.31       77.46    0.77\n",
      "  0     190          0.00          1.81       77.38    0.77\n",
      "  0     200          0.00          2.70       77.08    0.77\n",
      "  0     210          0.00          4.06       77.03    0.77\n",
      "  0     220          0.00          3.26       78.52    0.79\n",
      "  0     230          0.00          2.22       77.41    0.77\n",
      "  0     240          0.00          1.90       78.86    0.79\n",
      "  0     250          0.00          4.27       78.38    0.78\n",
      "  0     260          0.00          2.94       76.91    0.77\n",
      "  0     270          0.00          2.41       74.33    0.74\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train ./config/config-TextCatEnsemble.cfg --output ./models/textCatEnsemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-sleeping",
   "metadata": {},
   "source": [
    "# Evaluate our best model output and save metrics to disk\n",
    "\n",
    "For hyperparameter tuning, experimented with different BOW attributes and TexCatEnsemble parameters:\n",
    "\n",
    "- ngram_size = 4 (TODO: should try again with ngram_size = 2 after doign BOW analysis)\n",
    "- adjusted width to 128, nominal performance gain\n",
    "- tok2vec model embed attributed modified to include:\n",
    "    - \"ORTH\", \"LOWER\", \"NORM\", \"PREFIX\", \"SUFFIX\", \"SHAPE\", \"ID\"\n",
    "    - [2000, 2000, 1000, 1000, 1000, 1000]\n",
    "\n",
    "Also adjusted the width size from 64 to 96, which only resulted in a nominal increase in performance.\n",
    "\n",
    "Training was tested on training datasets of 100, 500, 1000 and finally, 5000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cognitive-rolling",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy evaluate ./models/textCatEnsemble/model-best ./data/dev.spacy --output ./evaluate/model-textCatEnsemble-metrics.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-planning",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy debug data ./config/config-TextCatEnsemble.cfg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-football",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
